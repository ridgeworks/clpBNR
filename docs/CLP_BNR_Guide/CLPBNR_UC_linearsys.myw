#### Solving Linear Systems

In theory, systems of linear equations are just constraints which should be amenable to the standard CLP techniques already described. In the real world, just as in solving for the roots of polynomials, things are not quite so simple. Consider the following two examples of simple linear systems in two variables:
eg
	?- [X,Y]::real, {X+2*Y==1,X-Y==1}.
	X:: 1.000000000000000...,
	Y::real(-1.1102230246251565e-16,5.551115123125783e-17).

	?- [X,Y]::real, {X+Y==1,X-Y==1}.
	﻿X::real(-1.0e+16,1.0e+16),
	Y::real(-1.0e+16,1.0e+16).
In the first example, the fixed point iteration immediately converged to an approximate solution (`X=1, Y=0`), while in the second (almost identical) example, the fixed point iteration did not converge at all. To help explain this observation, here are the graphs of the two systems:
[FPconvergance]
The red and blue lines are the equations and the solid black lines represent fixed point iteration steps. In the case of no convergence, these steps form a square box (equations intersect at 90 degrees). This means that a fixed point is quickly reached but no narrowing occurs. In the convergent case, each iteration step results in a narrowing of the `X` or `Y` interval, and a solution is found quite quickly. So the first issue is that fixed point convergence is data dependent. (Note this isn't unique to linear systems but it's easy to demonstrate it with these simple examples.)

Fortunately `solve/1` can be used overcome this deficiency:
eg
	?- [X,Y]::real, {X+Y==1,X-Y==1}, solve(X).
	﻿X:: 1.00000000...,
	Y::real(-8.257253769627937e-10,8.257253769627937e-10).
and, in this case, it works equally well if you solve for `X` or `Y` or both. However this may not always be the case. While the solution found should always be the same, the time taken to find it may vary widely (sometimes an order of magnitude or more). The following "real-world" examples were taken from [SYSTEMS OF LINEAR EQUATIONS AND MATRICES].

##### Manufacturing: Production Scheduling
>	"*Ace Novelty wishes to produce three types of souvenirs: types A, B, and C. To manufacture a type-A souvenir requires 2 minutes on machine I, 1 minute on machine II, and 2 minutes on machine III. A type-B souvenir requires 1 minute on machine I, 3 minutes on machine II, and 1 minute on machine III. A type-C souvenir requires 1 minute on machine I and 2 minutes each on machines II and III. There are 3 hours available on machine I, 5 hours available on machine II, and 4 hours available on machine III for processing the order. How many souvenirs of each type should Ace Novelty make in order to use all of the available time?*"

This can be simply modeled by:
.pl
	ace_produce([A,B,C],[MI,MII,MIII]) :-
		[A,B,C]::integer(0,_),   % numbers of each type to produce
		{
		   MI == 2*A + B + C,    % jobs for machine I
		  MII == A + 3*B + 2*C,  % jobs for machine II
		 MIII == 2*A + B + 2*C   % jobs for machine III
		}.
Fixed point iteration alone is insufficient but `solve` quickly finds the solution:
eg
	?- ace_produce([A,B,C],[180,300,240]).
	A::integer(0,90),
	B::integer(0,100),
	C::integer(0,120).

	?- ace_produce([A,B,C],[180,300,240]),solve(A).
	A = 36,
	B = 48,
	C = 60 ;
	false.
So Ace Novelty should make 36 type-A souvenirs, 48 type-B souvenirs, and 60 type-C souvenirs.

##### Capital Expenditure Planning
>	"*The management of Hartman Rent-A-Car has allocated $1.5 million to buy a fleet of new automobiles consisting of compact, intermediate-size, and full-size cars. Compacts cost $12,000 each, intermediate-size cars cost $18,000 each, and full-size cars cost $24,000 each. If Hartman purchases twice as many compacts as intermediate-size cars and the total number of cars to be purchased is 100, determine how many cars of each type will be purchased. (Assume that the entire budget will be used.)*"
eg
	﻿?- [C,I,F]::integer(0,_), {C+I+F==100,12000*C+18000*I+24000*F==1500000,C==2*I}.
	﻿C::integer(0,100),
	I::integer(0,50),
	F::integer(0,62).

	﻿?- [C,I,F]::integer(0,_), {C+I+F==100,12000*C+18000*I+24000*F==1500000,C==2*I}, solve(C).
	C = 60,
	I = 30,
	F = 10 ;
	false.
As above, the dependency issue requires the use of `solve/1` to generate a solution.  

##### Simple D.C. Circuit Analysis
This example has been included because [Towards Practical Interval Constraint Solving in Logic Programming] documents it as a linear system problem that is not handled well (at all?) by the CLP techniques described so far. Consider the D.C. circuit:
[SimpleCircuit]
The problem as stated is to solve for the currents flowing through the resistors assuming {`V=10`} volts and {`R_i = i Omega "for" i=1,2,...,9`}. The arrows indicate the direction of positive current flow. For the most part they are somewhat arbitrary; a negative value just means the flow is in the opposite direction. Applying Kirchhoff's laws yields the following equations:
.am
	    I_s-I_1-I_2-I_8 = 0,                                 I_1 = 10,
	       -I_s+I_1+I_7 = 0,                   2I_2-3I_3-8I_8 = 0,
	           I_2+I_3-I_5 = 0,                3I_3+5I_5-9I_9 = 0,
	 -I_3-I_4+I_8-I_9 = 0,             -4I_4+6I_6+9I_9 = 0,
	           I_4+I_6-I_7 = 0,  -I_1+4I_4+7I_7+8I_8 = 0,
	           I_5-I_6+I_9 = 0
As the paper states, there are 11 equations in 10 unknowns, but it's not obvious where the redundancy occurs. (Further it is suggested that initial ranges of `[-100,100]` be used for all intervals, although except for one case, this is not really necessary.)

However consider {`I_s`}. From the equations, it is not obvious that it cannot be negative. But that implies that positive current can flow from the negative to the positive terminals of the voltage supply. Furthermore any search, e.g., using `solve/1`, will spend considerable effort attempting to find solutions where this can occur. (The paper cited indicates either no answer was achieved within 24 hours on a 2 MIP CPU or no narrowing occurs even using `solve`.) But adding the simple constraint {`Is>=0`} generates the answer within a second or two (machine dependent). The CLP(BNR) code to define the circuit:
.pl
	simpleCircuit(Vs) :-
		simpleCircuitDef(Vs,EQs),  % EQs is list of constraint equations in Vs
		Vs::real,                  % declare so intervals are finite
		{EQs}.                     % activate constraints

	simpleCircuitDef([Is,I1,I2,I3,I4,I5,I6,I7,I8,I9],
		[
		 Is-I1-I2-I8 == 0,                 I1 == 10,
		   -Is+I1+I7 == 0,     2*I2-3*I3-8*I8 == 0,
			I2+I3-I5 == 0,     3*I3+5*I5-9*I9 == 0,
		-I3-I4+I8-I9 == 0,    -4*I4+6*I6+9*I9 == 0,
			I4+I6-I7 == 0, -I1+4*I4+7*I7+8*I8 == 0,
			I5-I6+I9 == 0
		]).
Again, no narrowing occurs in the initial fixed point iteration, but it's not obvious which variables to use with `solve`. As `solve` takes a list of variables (breadth first across all intervals named) there's no reason not to use the entire set of interval values:
eg
	?- Vs=[Is,I1,I2,I3,I4,I5,I6,I7,I8,I9], simpleCircuit(Vs).
	Vs = [Is, 10, I2, I3, I4, I5, I6, I7, I8|...],
	I1 = 10,
	Is::real(-9.99999999999999e+15, 1.0e+16),
	I2::real(-1.0e+16, 1.0e+16),
	I3::real(-1.0e+16, 1.0e+16),
	I4::real(-1.0e+16, 1.0e+16),
	I5::real(-1.0e+16, 1.0e+16),
	I6::real(-1.0e+16, 1.0e+16),
	I7::real(-1.0e+16, 9.99999999999999e+15),
	I8::real(-6.25e+15, 6.25e+15),
	I9::real(-8.888888888888889e+15, 8.888888888888889e+15).
	
	?- Vs=[Is,I1,I2,I3,I4,I5,I6,I7,I8,I9], simpleCircuit(Vs), solve(Vs).
	Vs = [Is, 10, I2, I3, I4, I5, I6, I7, I8|...],
	I1 = 10,
	Is:: 10.8282986...,
	I2:: 0.5690898...,
	I3:: -0.3118300...,
	I4:: 0.5320600...,
	I5:: 0.2572598...,
	I6:: 0.2962385...,
	I7:: 0.8282986...,
	I8:: 0.2592087...,
	I9:: 0.0389787... ;
	false.
Using `solve` finds the solution in a few seconds, but adding the constraint that {`Is`} is positive further reduces the execution time by over a factor of three:
eg
	?- Vs=[Is,I1,I2,I3,I4,I5,I6,I7,I8,I9], simpleCircuit(Vs), time(solve(Vs)).
	% 8,887,111 inferences, 1.550 CPU in 1.554 seconds (100% CPU, 5731804 Lips)
	Vs = [Is, 10, I2, I3, I4, I5, I6, I7, I8, I9],
	I1 = 10,
	Is:: 10.8282986...,
	I2:: 0.5690898...,
	I3:: -0.3118300...,
	I4:: 0.5320600...,
	I5:: 0.2572598...,
	I6:: 0.2962385...,
	I7:: 0.8282986...,
	I8:: 0.2592087...,
	I9:: 0.0389787... .
	
	?- Vs=[Is,I1,I2,I3,I4,I5,I6,I7,I8,I9], simpleCircuit(Vs), {Is>=0}, time(solve(Vs)).
	% 2,258,071 inferences, 0.437 CPU in 0.438 seconds (100% CPU, 5169742 Lips)
	Vs = [Is, 10, I2, I3, I4, I5, I6, I7, I8, I9],
	I1 = 10,
	Is:: 10.828298...,
	I2:: 0.5690898...,
	I3:: -0.3118300...,
	I4:: 0.5320600...,
	I5:: 0.2572598...,
	I6:: 0.2962385...,
	I7:: 0.828298...,
	I8:: 0.2592087...,
	I9:: 0.0389787... .
This example demonstrates the importance of ensuring that all known constraints are explicit to minimize execution time, even if some of the constraints seem redundant. In this case `solve` can spend  much wasted time searching for solutions for negative `Is`.

##### Under and Overdetermined Systems
The examples above are nicely behaved but what happens if the system of equations is under or overdetermined? In case of the latter, incompatible additional constraints should result in failure:
eg
	?- [X,Y]::real, {X+2*Y==4,X-2*Y==0,4*X+3*Y==12}.
	false.
In the under-determined case, little or no narrowing occurs regardless of how hard `solve` tries to find a solution:
eg
	?- [X,Y,Z,W]::real, {X+2*Y-3*Z+W== -2, 3*X-Y-2*Z-4*W==1, 2*X+3*Y-5*Z+W== -3}, solve([X,Y,Z,W]).
	﻿X::real(-1.0e+16, 1.0e+16),
	W::real(-1.0e+16, 1.0e+16),
	Y::real(-1.0e+16, 1.0e+16),
	Z::real(-1.0e+16, 1.0e+16).
But there are cases where under-determined still yield meaningful results. From the same source as previous examples:
>	"*Traffic Control (The figure) shows the flow of downtown traffic in a certain city during the rush hours on a typical weekday. The arrows indicate the direction of traffic flow on each one-way road, and appears beside each road. 5th Avenue and 6th Avenue can each handle up to 2000 vehicles per hour without causing congestion, whereas the maximum capacity of both 4th Street and 5th Street is 1000 vehicles per hour. The flow of traffic is controlled by traffic lights installed at each of the four intersections.*"
[Figure 7 Traffic]
"Without congestion" implies that all traffic entering an intersection must leave the intersection. Including the street volume limits, the system can be modelled as:
```
﻿?- [X1,X3]::integer(0,2000), [X2,X4]::integer(0,1000), {X1+X4==1500, X1+X2==1300, X2+X3==1800, X3+X4==2000}.
X1::integer(500, 1300),
X3::integer(1000, 1800),
X2::integer(0, 800),
X4::integer(200, 1000).
```
Note that `solve` is unnecessary  here. This isn't a unique solution (the system is under-determined) but the results are useful in that they specify limits to traffic flows while avoiding congestion. Further constraints can be applied to model other possible scenarios, e.g.,
>	"*Suppose the part of 4th Street between 5th Avenue and 6th Avenue is to be resurfaced and that traffic flow between the two junctions must therefore be reduced to at most 300 vehicles per hour.*"
yielding:
```
﻿?- [X1,X3]::integer(0,2000), [X2,X4]::integer(0,1000), {X1+X4==1500, X1+X2==1300, X2+X3==1800, X3+X4==2000}, {X4=<300}.
X1::integer(1200, 1300),
X3::integer(1700, 1800),
X2::integer(0, 100),
X4::integer(200, 300).
```
Congestion does not occur as long as `X2` remains below 100, since exceeding that will cause congestion at the intersection of 5th Street and 5th Avenue.

##### Cramer's Rule
Solving systems of linear equations by specifying the equations as constraints and performing a bifurcating search (`solve/1`) is a rather brute force approach when there are several [well known algorithms] for doing the same thing. One such algorithm is [Cramer's rule] which states that if you can represent the system of equations in matrix form {`A*bb"x"=bb"b"`} where {`A`} is an {`n xx n`} matrix of coefficients, and {`bb"b"`} and {`bb"x"`} are {`n`}-dimensional column vectors, then {`bb"x" = A^-1*bb"b"`}.

Using `library(type_ndarray)`in the [`arithmetic_types`] pack for matrix support, the "Production Scheduling" problem described above can be simply solved (without constraints):
eg
	﻿?- set_prolog_flag(prefer_rationals,true).
	true.
	
	﻿?- use_module(library(type_ndarray)).
	true.
	
	?- Am is ndarray([[2,1,1],[1,3,2],[2,1,2]]), Bs is ndarray([[180],[300],[240]]), Xs is ndarray([[A],[B],[C]]),
	Xs is dot(inverse(Am),Bs).
	
	Am = #(#(2, 1, 1), #(1, 3, 2), #(2, 1, 2)),
	Bs = #(#(180), #(300), #(240)),
	Xs = #(#(36), #(48), #(60)),
	A = 36,
	B = 48,
	C = 60.
The function `ndarray/1` creates an N dimensional array from a nested list representation while the `dot/2` and `inverse/1` functions calculate the dot product and matrix inverse. (Rational number calulations are enabled to avoid floating point rounding errors.) Functions on type `ndarray` are constraint aware, so as long as the array structure has been defined, the order of the goals can be changed enabling the common test and generate pattern:
eg
	﻿?- Am is ndarray([[2,1,1],[1,3,2],[2,1,2]]), Bs is new(ndarray,[3,1]),
	ndarray([[A],[B],[C]]) is dot(inverse(Am),Bs),
	Bs is transpose(ndarray([180,300,240])).
	
	Am = #(#(2, 1, 1), #(1, 3, 2), #(2, 1, 2)),
	Bs = #(#(180), #(300), #(240)),
	A = 36,
	B = 48,
	C = 60.

The "Expenditure Planning" problem is similarly straight forward:
eg
	?- Am is ndarray([[1,1,1],[12000,18000,24000],[1,-2,0]]), Bs is ndarray([[100],[1500000],[0]]),
	ndarray([[C],[I],[F]]) is dot(inverse(Am),Bs).
	
	Am = #(#(1, 1, 1), #(12000, 18000, 24000), #(1, -2, 0)),
	Bs = #(#(100), #(1500000), #(0)),
	C = 60,
	I = 30,
	F = 10.

The solution to the "Simple Circuit" analysis isn't quite so clear. Cramer's rule requires a square coefficient matrix, while the simple circuit has 11 equations in 10 unknowns. On obvious approach might be to discard the `I1 = 10` equation and using the remaining 10 (while unifying `I1` with `10`). But there is no inverse for the resulting coefficient matrix (`Am`), as the determinant of the matrix is `0` (using the coefficient ordering corresponding to `[I1,I2,I3,I4,I5,I6,I7,I8,I9,Is]`):
eg
	﻿?- Am is ndarray([
	[-1,-1, 0, 0, 0, 0, 0,-1, 0, 1],
	[ 1, 0, 0, 0, 0, 0, 1, 0, 0,-1],
	[ 0, 1, 1, 0,-1, 0, 0, 0, 0, 0],
	[ 0, 0,-1,-1, 0, 0, 0, 1,-1, 0],
	[ 0, 0, 0, 1, 0, 1,-1, 0, 0, 0],
	[ 0, 0, 0, 0, 1,-1, 0, 0, 1, 0],
	[ 0, 2,-3, 0, 0, 0, 0,-8, 0, 0],
	[ 0, 0, 3, 0, 5, 0, 0, 0,-9, 0],
	[ 0, 0, 0,-4, 0, 6, 0, 0, 9, 0],
	[-1, 0, 0, 4, 0, 0, 7, 8, 0, 0]
	]), Det is determinant(Am).
	Am = #(#(-1, -1, 0, 0, 0, 0, 0, -1, 0, 1), #(1, 0, 0, 0, 0, 0, 1, 0, 0, -1), #(0, 1, 1, 0, -1, 0, 0, 0, 0, 0), #(0, 0, -1, -1, 0, 0, 0, 1, -1, 0), #(0, 0, 0, 1, 0, 1, -1, 0, 0, 0), #(0, 0, 0, 0, 1, -1, 0, 0, 1, 0), #(0, 2, -3, 0, 0, 0, 0, -8, 0, 0), #(0, 0, 3, 0, 5, 0, 0, 0, -9, 0), #(0, 0, 0, -4, 0, 6, 0, 0, 9, 0), #(-1, 0, 0, 4, 0, 0, 7, 8, 0, 0)),
	Det = 0.
Since it's not obvious which equation may be redundant, experimentation can be used to find a non-zero determinant by replacing the first equation by `I1 = 10`. A new predicate to support the matrix form of the circuit definition:
.pl
	simpleCircuitDef(Currents,Am,Bs,Xs) :-
		Xs is transpose(ndarray(Currents)),
		Am is ndarray([
		[ 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
		[ 1, 0, 0, 0, 0, 0, 1, 0, 0,-1],
		[ 0, 1, 1, 0,-1, 0, 0, 0, 0, 0],
		[ 0, 0,-1,-1, 0, 0, 0, 1,-1, 0],
		[ 0, 0, 0, 1, 0, 1,-1, 0, 0, 0],
		[ 0, 0, 0, 0, 1,-1, 0, 0, 1, 0],
		[ 0, 2,-3, 0, 0, 0, 0,-8, 0, 0],
		[ 0, 0, 3, 0, 5, 0, 0, 0,-9, 0],
		[ 0, 0, 0,-4, 0, 6, 0, 0, 9, 0],
		[-1, 0, 0, 4, 0, 0, 7, 8, 0, 0]
		]),	
		Bs is transpose(ndarray([10.0,0,0,0,0,0,0,0,0,0])).
Now:
eg
	﻿?- simpleCircuitDef([I1,I2,I3,I4,I5,I6,I7,I8,I9,Is],Am,Bs,Xs),Xs is dot(inverse(Am),Bs).
	I1 = 10.0,
	I2 = 0.5690898460339116,
	I3 = -0.3118300526213214,
	I4 = 0.5320600272851296,
	I5 = 0.25725979341259014,
	I6 = 0.2962385499902553,
	I7 = 0.8282985772753849,
	I8 = 0.25920873124147337,
	I9 = 0.038978756577665176,
	Is = 10.828298577275387,
	Am = #(#(1, 0, 0, 0, 0, 0, 0, 0, 0, 0), #(1, 0, 0, 0, 0, 0, 1, 0, 0, -1), #(0, 1, 1, 0, -1, 0, 0, 0, 0, 0), #(0, 0, -1, -1, 0, 0, 0, 1, -1, 0), #(0, 0, 0, 1, 0, 1, -1, 0, 0, 0), #(0, 0, 0, 0, 1, -1, 0, 0, 1, 0), #(0, 2, -3, 0, 0, 0, 0, -8, 0, 0), #(0, 0, 3, 0, 5, 0, 0, 0, -9, 0), #(0, 0, 0, -4, 0, 6, 0, 0, 9, 0), #(-1, 0, 0, 4, 0, 0, 7, 8, 0, 0)),
	Bs = #(#(10.0), #(0), #(0), #(0), #(0), #(0), #(0), #(0), #(0), #(0)),
	Xs = #(#(10.0), #(0.5690898460339116), #(-0.3118300526213214), #(0.5320600272851296), #(0.25725979341259014), #(0.2962385499902553), #(0.8282985772753849), #(0.25920873124147337), #(0.038978756577665176), #(10.828298577275387)).
Where applicable, using standard numerical methods, with or without constraints, is usually a more optimal approach than a general purpose search technique like `solve/1`, yielding more precise results in less time. On the other hand, if the problem consists of mixed linear and non-linear equations or fails to meet the necessary requirements, e.g., the coefficient matrix isn't square, "constrain and search" may offer a feasible alternative.

<#TableOfContents>

&
	[SYSTEMS OF LINEAR EQUATIONS AND MATRICES] <- link https://docplayer.net/21711942-The-linear-equations-in-two-variables-studied-in.html
	[Towards Practical Interval Constraint Solving in Logic Programming] <- link https://pdfs.semanticscholar.org/1dca/e2a910184c4b2f9d770f054168150c6d0bde.pdf
	[FPconvergance]  <- image images/linearConvergance.png width=50% height=50% style="margin-left:200px"
	[SimpleCircuit] <- image images/SimpleCircuit.png  width=50% height=50% style="margin-left:200px"
	[Figure 7 Traffic] <- image images/TrafficExample5.png  width=30% height=30% style="margin-left:200px"
	[Appendix 1] <- link #toc4Appendix_1_-__linear.pl__Source
	[well known algorithms] <- link https://en.wikipedia.org/wiki/System_of_linear_equations
	[Cramer's rule] <- link https://en.wikipedia.org/wiki/Cramer%27s_rule
	[`arithmetic_types`] <- link https://www.swi-prolog.org/pack/list?p=arithmetic_types