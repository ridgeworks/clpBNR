#### Using Metalevel Contractors

Other implementations of CLP over intervals have been characterized as either "RISC" or "CISC" designs (see [CLIP]). In the RISC approach each constraint is broken down into a sequence of low level primitives which are "executed" by the constraint engine (fixed point iterator). However, as seen in previous examples, narrowing of the internal fixed point iteration can be weak due to the dependency issue. CISC systems try to address this problem by treating the constraint as a single entity but this requires a more powerful solver. CLIP and CLP(BNR) are RISC designs; [Newton] and [Numerica] are CISC designs. To overcome some of the RISC limitations, CLIP introduced the concept of metalevel contractors which are a way of adding redundant constraints which can accelerate the convergence of the fixed point iteration. Relative to CISC designs, this has performance implications, but can be accomplished without complicating the underlying constraint infrastructure.

aside> Aside: With conventional floating point arithmetic, adding redundant equations must be done carefully because they can exacerbate problems caused by rounding errors. Using sound interval arithmetic, these problems are avoided and redundancy can be used to accelerate convergence. (See also [Algorithmic Power from Declarative Use of Redundant Constraints]).

A contractor is just a procedure which forces some narrowing operation on a set of intervals. `solve`, `splitsolve` and `absolve`, as defined in the `clpBNR` package, are contractors bundled with an iterating algorithm that terminates when some condition is met, e.g., the width of the interval(s) is less than some value. Module `clpBNR_toolkit` (included with pack `clpBNR`) exports additional contractors that split intervals at their midpoint; `mid_split_one/1` selects the largest interval (by width) from a list. It uses `mid_split/1` which takes a single interval as its argument and splits it as long as the interval doesn't pass the `small` test, as defined by `clpBNR:small/1`. The implementation looks like:
.pl
	%
	% contractor to split a single interval on midpoint if sufficiently wide (creates a choicepoint)
	%
	mid_split(X) :- small(X), !.    % too narrow to split
	mid_split(X) :-
		M is midpoint(X),
		({X=<M} ; {M=<X}).
If the interval is splittable, a constraint is applied to first test the lower half of the interval leaving a choicepoint due to `;/2` so the upper half will be tested on backtracking. The obvious redundant constraints provide no additional information but merely define two halves of the problem that can be independently explored, hopefully resulting in failure so that the interval can be narrowed to the other half. If further splitting is required, an iterator becomes necessary to keep the process going. Module `clpBNR_toolkit` exports `iterate_until/3` for that purpose:
.pl
	%
	% General purpose iterator: execute Goal a maximum of N times or until Test succeeds
	%
	iterate_until(N,Test,Goal) :- N>0, !, 
		Goal,
		N1 is N-1,
		(Test
		 -> true
		  ; iterate_until(N1,Test,Goal)
		).
	iterate_until(_N,_,_).  % non-positive N --> exit
The labelling predicates exported from module `clpBNR`, e.g., `solve` and `splitsolve`, include both a contractor and an iterator. The contractor implemented by `splitsolve/1` is equivalent to `midpoint_split_one/1` which is also exported by `clpBNR_toolkit`; it takes a a list of intervals, selects the one with the largest width, and then uses `mid_split/1` (described above).   

A few simple examples from previous sections using the `mid_split` and `mid_split_one` contractors with `iterate_until`:
eg
	?- X::real, {X**4-4*X**3+4*X**2-4*X+3==0}, iterate_until(50,small(X),mid_split(X)).
	X:: 1.000000... ;
	X:: 3.00000... ;
	false.
	
	?- {X**2+Y**2==2, Y-X**2==0}, iterate_until(50,small([X,Y]),mid_split_one([X,Y])).
	X:: -1.00000000000000...,
	Y:: 1.00000000000000... ;
	X:: 1.00000000000000...,
	Y:: 1.00000000000000... .
 In each case the contractor `mid_split_one` is used until the limit of 50 iterations is reached or until all variables are "small" enough (as defined by `clpBNR:small/1`). This demonstrates the general principle of combining a general purpose iterator with a simple contractor but the real value comes when the functionality of built-in CISC style contractors can be replicated in much the same way.
 
##### A Multivariate Taylor Contractor

The Taylor series expansion of a function can be used to define redundant constraints which can accelerate the convergence of the fixed point iteration. For a multivariate equation of the form 
math>  f(x_1,...x_i,...x_n) = 0
a redundant constraint of the form
math>  0 = f(a_i)+f'(xi_i)*(x_i-a_i) , xi_i = a_i+t_i*(x_i-a_i) , 0<=t_i<=1
can be added for each {`i`}, where {`a_i`} is some value in the domain of {`x_i`}. Usually the best convergence occurs when {`a_i`} is the midpoint of {`x_i`}. (For a more complete description of the underlying math see [CLIP].)

The `clpBNR_toolkit` exports `taylor_contractor/2` which takes an equation of the form `E1 == E2` and generates a centred form contractor `cf_contractor(Xs,As)` which can be used in an iterator in much the same way as `mid_split` in the example above. Note that the act of constructing a Taylor contractor is separate from applying it (using `iterate_until/3`). In the process, the original equation (as a constraint) and any redundant constraints are added to the system. There is a requirement that the expression `E1-E2` be differentiable over the range of the variables it contains. The `Xs` and `As` correspond to the {`x_i`}'s and {`a_i`}'s in the equations defined above.

The actual code to build the Taylor contractor is somewhat complicated but it essentially applies additional constraints which improve narrowing convergence. (See the source code for `clpBNR_toolkit` for details.) These constraints are fired when the constructed centred form contractor is called within an iteration loop, effectively replacing the search strategy of `solve/1` which creates sub-problems by splitting intervals in hope that many of the sub-problems contain no solutions. The alternative to `solve/1` when using a centred form contractor is `cf_solve/1` which takes as its single argument a centred form contractor such as that generated by `taylor_contractor/2`.  Used in this way, contractors can be can be used as an alternative to `solve` and `absolve` to find roots of polynomial equations (as done in [Solving Polynomial Equations in one Variable]).  In general, this provides better results (narrower intervals and fewer "false positives") in a fraction of the time: 
eg
	?- X::real, taylor_contractor({X**2-4*X+3==0},T), cf_solve(T).
	T = cf_contractor([X], [_A]),
	X:: 1.000000000000000...,
	_A::real(-1.0Inf, 1.0Inf) ;
	T = cf_contractor([X], [_A]),
	X:: 3.00000000000000...,
	_A::real(-1.0Inf, 1.0Inf).
Constructing a Taylor contractor and solving it is such a common scenario that these two operations are wrapped in a single predicate, `taylor_solve/1` for this purpose and which also conveniently hides the contractor details for these examples:
eg
	?- X::real, taylor_solve({X**2-4*X+3==0}).
	X:: 1.000000000000000... ;
	X:: 3.00000000000000... .
	
	?- X::real, taylor_solve({17*X**256+35*X**17-99*X==0}).
	X:: 0.0000000000000000... ;
	X:: 1.005027892894011... .
	
	?- X::real, taylor_solve({35*X**256-14*X**17+X==0}).
	X:: -0.847943660827315... ;
	X:: 0.0000000000000000... ;
	X:: 0.847943660827315... ;
	X:: 0.995842494200498... .
	
	?- X::real, taylor_solve({X**4-12*X**3+47*X**2-60*X==0}).
	X:: 0.0000000000000000... ;
	X:: 3.00000... ;
	X:: 4.00000000... ;
	X:: 5.0000000... ;
	false.
	
	?- X::real, taylor_solve({X**2-2*X+1==0}).
	X:: 1.000... ;
	false.
The following table compares `solve` and `taylor_solve` in terms of narrowing operations performed (should be relatively implementation and machine independent). And for a subset of the examples the effects of using Horner notation has been added to highlight the effects of combining techniques:
.myw
	.tsv
		Polynomial						`solve`			`solve_Hnr`		`Taylor`		`Taylor_Hnr`
		`X**2-4*X+3`					`   776`		`    221`		`   809`		`    265`
		`X**4-4*X**3+4*X**2-4*X+3`		` 14057`		`   6802`		` 11741`		`   6380`
		`17*X**256+35*X**17-99*X`		`   215`		` `				`   321`		` `
		`35*X**256-14*X**17+X`			`  2500`		` `				`  4107`		` `
		`X**4-12*X**3+47*X**2-60*X`		`155542`		`  15092`		` 20089`		`  18677`
		`X**2-2*X+1`					`111671`		`  53622`		` 63204`		`  37438`
	&	// local styles for table
		@css
			table.my_array { border-collapse:collapse; }
			table.my_array tr td { background:whitesmoke; padding: 4px 16px; }
			table.my_array tr:nth-child(1) td { background:lightgray; }

The results demonstrate that Taylor is generally effective, particularly on compute intensive cases, but not universally so. Using a Taylor contractor entails overhead due to the additional contraints. This usually improves the efficiency of local propagation, but may not be enough to overcome the additional overhad. It all depends on the problem at hand.

Combining contractors with Horner representation can yield further gains in many (but not all) cases. (Multiple roots at one value are usually problematical since it can be difficult to separate them within precision limits; as an exercise try `X**4-X**3-3*X**2+5*X-2` which has a root at `X= -2` and a triple root at `X=1`.)

Problems involving multiple variables typically require more than one equation. Since the variables are shared, the generated Taylor contractors (one per equation) can be merged into a single contractor by omitting duplicates. `taylor_contractor/2` also accepts a sequence or list of equations and constructs a single `cf_contractor` for use in an iterator. Examples of using this predicate follow.

##### The Broyden Banded Function

A common example in interval arithmetic publications is the Broyden banded function which defines the following system of {`n`} equations in {`n`} variables {`{x_1,...,x_n}`}:
math> x_i*(2+5x_i^2) = sum_(i-5<=j<=i+1,j!=i,jin[1,n])x_j*(x_j+1)
A predicate to generate this set of equations for different values of `N`:
.pl
	broyden(N,Vs,EQs) :-
		length(Vs,N),
		cbbf(1,N,Vs,Vs,EQs), !.
	
	cbbf(I, N, [Xi|Xs], L, [2*Xi + 5*Xi**3 + 1 == Si|Rest]) :-   % rewrite Xi*(2+5*Xi**2) + 1 == Si
		make_si(1,I,N,L,0,Si),
		I1 is I+1,
		cbbf(I1,N,Xs,L,Rest).
	cbbf(_I,_N,[],_,[]).
	
	make_si(J,_,N,_,S,S)         :- J > N , !.                       % terminate
	make_si(J,I,N,[Xj|Xs],S1,S)  :- I-5 =< J, J =< I+1, I\==J,  !,   % add a term
	  J1 is J+1,
	  make_si(J1,I,N,Xs,S1 + Xj*(1+Xj),S).
	make_si(J,I,N,[_Xj|Xs],S1,S) :-                                  % skip
	  J1 is J+1,
	  make_si(J1,I,N,Xs,S1,S).
Using `solve` will generate the correct result; for `N=5`:
eg
	?- broyden(5,Vs,Es), Vs::real(-1,1), {Es}, solve(Vs).
	Vs = [_A, _B, _C, _D, _E],
	Es = [2*_A+5*_A**3+1==0+_B*(1+_B), 2*_B+5*_B**3+1==0+_A*(1+_A)+_C*(1+_C), 2*_C+5*_C**3+1==0+_A*(1+_A)+_B*(1+_B)+_D*(1+_D), 2*_D+5*_D**3+1==0+_A*(1+_A)+_B*(1+_B)+_C*(1+_C)+_E*(1+_E), 2*_E+5*_E**3+1==0+_A*(1+_A)+_B*(1+_B)+_C*(1+_C)+_D*(1+_D)],
	_A:: -0.42830...,
	_B:: -0.47659...,
	_C:: -0.51963...,
	_D:: -0.55886...,
	_E:: -0.55886... ;
	false.
Using a Taylor contractor:
eg
	?- broyden(5,Vs,Es), Vs::real(-1,1), taylor_solve({Es}).
	Vs = [_A, _B, _C, _D, _E],
	Es = [2*_A+5*_A**3+1==0+_B*(1+_B), 2*_B+5*_B**3+1==0+_A*(1+_A)+_C*(1+_C), 2*_C+5*_C**3+1==0+_A*(1+_A)+_B*(1+_B)+_D*(1+_D), 2*_D+5*_D**3+1==0+_A*(1+_A)+_B*(1+_B)+_C*(1+_C)+_E*(1+_E), 2*_E+5*_E**3+1==0+_A*(1+_A)+_B*(1+_B)+_C*(1+_C)+_D*(1+_D)],
	_A:: -0.428302864642...,
	_B:: -0.476596531501...,
	_C:: -0.519637722100...,
	_D:: -0.558861956527...,
	_E:: -0.558861956527... ;
	false.
Comparing performance, using the Taylor contractor produces a sharper answer than `solve` in a fraction of the time for small values of `N` (e.g., 5), and even better performance for larger `N`. If the initial domain is large (rather than `real(-1,1)`), a mild treatment of `absolve` can be used to "pre-shrink" the domains with little impact on the execution times. For this case:
eg
	?- broyden(20,Vs,Es), Vs::real, {Es}, absolve(Vs,2), taylor_solve({Es}).
	Vs = [_A, _B, _C, _D, _E, _F, _G, _H, _I|…],
	Es = [2*_A+5*_A**3+1==0+_B*(1+_B), 2*_B+5*_B**3+1==0+_A*(1+_A)+_C*(1+_C), 2*_C+5*_C**3+1==0+_A*(1+_A)+_B*(1+_B)+_D*(1+_D), 2*_D+5*_D**3+1==0+ … * … + _B*(… + …)+_C*(1+_C)+_E*(1+_E), 2*_E+5* … ** … + 1== … + … + … * … + _D*(… + …)+_F*(1+_F), … * … + … * … + 1== … + … + … * … + _G*(… + …), … + … + 1== … + … + … * …, … + … == … + …, … == …|…],
	_A:: -0.428303...,
	_B:: -0.476596...,
	_C:: -0.519652...,
	_D:: -0.558099...,
	_E:: -0.592506...,
	_F:: -0.62450...,
	_G:: -0.623238...,
	_H:: -0.621419...,
	_I:: -0.619616...,
	_J:: -0.618226...,
	_K:: -0.617518...,
	_L:: -0.617731...,
	_M:: -0.617900...,
	_N:: -0.6180078...,
	_O:: -0.6180570...,
	_P:: -0.6180627...,
	_Q:: -0.6180472...,
	_R:: -0.6180112...,
	_S:: -0.61887208...,
	_T:: -0.58627694... ;
	false.
Execution times were over ten times faster using the `absolve` pre-shrink than without it. Rurthermore this solution this scales approximately linearly with 'N'.
 
##### Ebers and Moll Transistor Model

One of the more challenging examples in the literature is the Ebers-Moll transistor model consisting of 9 non-linear equations in 9 variables. From [Progress in the solving of a circuit design problem]:
>	"*Ebers and Moll’s circuit design problem [6] is considered as a challenging benchmark for local and global methods. Recently, two interval-based techniques were successfully applied: Ratschek and Rokne’ algorithm [17] has derived the solution with a precision of four significant digits in about fourteen months using a network of thirty Sun Sparc 1 workstations; Puget and Van Hentenryck’ method [16] has solved the problem with a precision of eight significant digits in about forty minutes using a Sun Sparc UltraII workstation (the improvement is great though different machines were used).*"
The quoted paper reports further algorithmic improvements resulting in 12 digit accuracy in less than 10 minutes. While `clpBNR`, being a wholly Prolog implementation, is not at all competitive on performance, this a good example of what issues can arise given such a "challenging" problem.

The Prolog definition of the Ebers and Moll transistor example:
.pl
	ebers_moll(Vs,Es) :-
		Vs=[X1,X2,X3,X4,X5,X6,X7,X8,X9],
		G1s=g1(0.485,0.752,0.869,0.982),
		G2s=g2(0.369,1.254,0.703,1.455),
		G3s=g3(5.2095,10.0677,22.9274,20.2153),
		G4s=g4(23.3037,101.779,111.461,191.267),
		G5s=g5(28.5132,111.8468,134.3844,211.4823),
		eq1s(Vs,G1s,G2s,G3s,G4s,G5s,Eq1s),
		eq2s(Vs,G1s,G2s,G3s,G4s,G5s,Eq2s),
		flatten([Eq1s,Eq2s,X1*X3-X2*X4==0],Es).
		 
	eq1s(Xs,G1s,G2s,G3s,G4s,G5s,Eqs) :- eq1s(4,Xs,G1s,G2s,G3s,G4s,G5s,Eqs).
	eq1s(0,Xs,G1s,G2s,G3s,G4s,G5s,[]) :-!.
	eq1s(K,Xs,G1s,G2s,G3s,G4s,G5s,[EqK|Eqs]) :-
		K1 is K-1, eq1s(K1,Xs,G1s,G2s,G3s,G4s,G5s,Eqs),
		eq1(K,Xs,G1s,G2s,G3s,G4s,G5s,EqK).
	
	eq2s(Xs,G1s,G2s,G3s,G4s,G5s,Eqs) :- eq2s(4,Xs,G1s,G2s,G3s,G4s,G5s,Eqs).
	eq2s(0,Xs,G1s,G2s,G3s,G4s,G5s,[]) :-!.
	eq2s(K,Xs,G1s,G2s,G3s,G4s,G5s,[EqK|Eqs]) :-
		K1 is K-1, eq2s(K1,Xs,G1s,G2s,G3s,G4s,G5s,Eqs),
		eq2(K,Xs,G1s,G2s,G3s,G4s,G5s,EqK).
		
	eq1(K,[X1,X2,X3,X4,X5,X6,X7,X8,X9|Ys],G1s,G2s,G3s,G4s,G5s,
		(1-X1*X2)*X3*(exp(X5*(G1K-G3K*X7*1e-3-G5K*X8*1e-3))-1)-G5K+G4K*X2 == 0
		) :-
		arg(K,G1s,G1K), arg(K,G3s,G3K), arg(K,G4s,G4K), arg(K,G5s,G5K).
	
	eq2(K,[X1,X2,X3,X4,X5,X6,X7,X8,X9|Ys],G1s,G2s,G3s,G4s,G5s,
		(1-X1*X2)*X4*(exp(X6*(G1K-G2K-G3K*X7*1e-3+G4K*X9*1e-3))-1)-G5K*X1+G4K == 0
		) :-
		arg(K,G1s,G1K), arg(K,G2s,G2K), arg(K,G3s,G3K), arg(K,G4s,G4K), arg(K,G5s,G5K).
Since the ranges of the variables are relatively small (`0` to `10`), and since the Taylor contractor is most effective in the middles of such ranges, using it would seem to be a desirable approach. However `cf_solve` (and `taylor_solve`) have an undesirable property in the context of this problem. Like `solve`, the selected point to subdivide an interval should not be in the vicinity of a solution in order to avoid the cluster problem discussed earlier. For the transistor problem under discussion, this results in a significant overhead and, as it turns out, no significant benefit. In fact using `cf-solve` fails to narrow the intervals sufficiently to be considered a useful answer.

As an alternative, a "custom" solver can be constructed using the piece parts already described above, primarily `iterate_until/3` with `mid_split` to force  splitting at the interval midpoint regardless of whether it's close to a solution point:
eg
	?- Vs=[X1,X2,X3,X4,X5,X6,X7,X8,X9],ebers_moll(Vs,Es),Vs::real(0,10),taylor_contractor({Es},T),time(iterate_until(12,small(Vs),(T,maplist(mid_split,Vs)))).
	% 31,383,368,268 inferences, 2021.937 CPU in 2023.211 seconds (100% CPU, 15521436 Lips)
	Vs = [X1, X2, X3, X4, X5, X6, X7, X8, X9],
	Es = [(1-X1*X2)*X3*(exp(X5*(… - … - … * …))-1)-211.4823+191.267*X2==0, (1-X1*X2)*X3*(exp(X5*(… - …))-1)-134.3844+111.461*X2==0, (1- … * …)*X3*(exp(… * …)-1)-111.8468+101.779*X2==0, (… - …)*X3*(exp(…)-1)-28.5132+23.3037*X2==0, … * … * (… - …)-211.4823*X1+191.267==0, … * … - … * … + 111.461==0, … - … + 101.779==0, … + … == 0, … == …],
	T = cf_contractor([X9, X6, X4, X8, X7, X5, X3, X2|…], [_A, _B, _C, _D, _E, _F, _G, _H|…]),
	X1:: 0.899998...,
	X2:: 0.4503...,
	X3:: 1.0013...,
	X4:: 2.0012...,
	X5:: 7.9968...,
	X6:: 8.000...,
	X7:: 4.999...,
	X8:: 0.9995...,
	X9:: 1.9992...,
	_I::real(-1.0Inf, 1.0Inf),
	_H::real(-1.0Inf, 1.0Inf),
	_G::real(-1.0Inf, 1.0Inf),
	_F::real(-1.0Inf, 1.0Inf),
	_E::real(-1.0Inf, 1.0Inf),
	_D::real(-1.0Inf, 1.0Inf),
	_C::real(-1.0Inf, 1.0Inf),
	_B::real(-1.0Inf, 1.0Inf),
	_A::real(-1.0Inf, 1.0Inf) .
It takes over half an hour (and over 31 billion inferences) to achieve an answer with 4 digits of precision, consistent with the literature. Better precision can be achieved by increasing the `Count` parameter to `iterate_until` but with an impact on execution time.  (It may also be necessary to define a higher precision value for the `small(Vs)` test.) And although this is a particularly challenging example, it serves to demonstrate the limitations of this implementation of CLP(BNR). 

##### Summary

CISC based interval constraint systems overcame deficiencies in RISC, such as slow convergence, by building sophisticated narrowing algorithms into the constraint engine. But metalevel contractors can overcome some of these deficiencies without complicating the underlying engine design. Advances in hardware and software (Prolog) results in comparable performance to earlier CISC implementations, although the comparison is a bit unfair and CISC engine implemented in C will always be faster than this implementation of CLP(BNR) on equivalent hardware. The other advantage of this metalevel design is that it facilitates experimentation with new contractors without understanding (or compromising) the details of the underlying constraint system. This facilitates the addition of "specialized" contractors that may be more effective for particular problem domains.

<#TableOfContents>

&
	[Solving Polynomial Equations in one Variable] <- link #toc4Solving_Polynomial_Equations_in_one_Variable
	[Progress in the solving of a circuit design problem] <- link https://www.researchgate.net/publication/2322545_Progress_in_the_Solving_of_a_Circuit_Design_Problem
	[Algorithmic Power from Declarative Use of Redundant Constraints] <- link https://maarten.vanemden.com/Publications/redund.pdf
	[Appendix 1] <- link #toc4Appendix_1_-__clpBNRmeta_contractor.pl__Source