#### Numerical Solution of Differential Equations

Many of the laws of physics (mechanics, thermodynamics, electromagnetics, ..) are expressed in the form of differential equations. Solving a differential equation is the process of mapping it to an equivalent equation which does not contain derivatives, which typically involves integration and the introduction of new constants. In many real world problems this cannot be done in an "exact" manner so numerical methods are employed to find solutions. Since such methods are based on approximations, this is a particularly fruitful are for expressing results as intervals which include the effects of such approximations in addition to floating point rounding errors. For example, numerical integration algorithms are prone to instability depending on the specific problem; such instability is explicitly manifested in the width of any interval results, compared with a single floating point result computed with conventional arithmetic.

##### Simple Integration of {`f(x)`}

Before considering the general problem of solving differential equations with multiple variables, we'll start with the problem of calculating the bounds of a simple integral: {`int_(Xl)^(Xh) f(X) dx`}. The value of an integral can be approximated numerically by multiplying the width of interval {`X`} ({`Xh-Xl`}) by the value of {`f(X)`} over the range of {`X`} (also an interval). However, this is only an approximation the width of the interval so calculated can be quite large. As is done in standard numerical integration techniques, this can be addressed by dividing {`X`} into {`N`} sub-intervals, calculating the integral for each, and adding them together. For sufficiently large {`N`}, the accumulated error can kept within acceptable limits and the result will always contain the real integral value.

Defining an "acceptable" value of {`N`} in general for any {`f(X)`} is problematical, so for the purposes of this example we'll use the {`2^P`} where the default value of {`P`} is the value of the `clpBNR_default_precision` environment flag. The interval value `R` of the integral of a function `F` over interval `X` can be done as follows:
.pl
	integrate(F,X,R,P) :-
		integrate_step(P,(F,X),X,Exp),
		add_constraint(R is Exp).               % {R is Exp}.  without checks
	
	integrate_step(0, F, Xstep, Fstep*Step) :- !,  % final step, integral is F(Xstep)*delta(Xstep)
		copy_term(F,(Fstep,Xstep)),                % copy of F for each step
		Step is delta(Xstep).
	integrate_step(C, F, XStep, IntL+IntR) :-      % divide current X in two and find integral of each half
		C > 0,                                     % fail on negative C
		Xm is midpoint(XStep),
		range(XStep,[Xl,Xh]),
		XL::real(Xl,Xm), XH::real(Xm,Xh),          % step for each half
		NxtC is C-1,
		integrate_step(NxtC,F,XL,IntL),
		integrate_step(NxtC,F,XH,IntR).
`integrate_step/4` produces a expression containing the sum of the sub-integrals, each of which is the product of the sub-interval width and the value of `F` over that sub-interval. As this expression cannot be further simplified, a `clpBNR` internal predicate (`constrain_`) is used to add the constraint for efficiency reasons. (Note that isn't much "constraining" going on here; we're just using interval arithmetic system to calculate the bounds of the integral.)

To integrate {`f(x) = x^2`} over the range {`0`} to {`1`} for `P` ranging from `2` to `10`:
eg
	?- X::real(0,1), between(2,10,P), integrate(X**2,X,R,P), range(R,[Rl,Rh]), format("~w:\t[~f,~f]\n",[P,Rl,Rh]),fail.
	2:	[0.218750,0.468750]
	3:	[0.273438,0.398438]
	4:	[0.302734,0.365234]
	5:	[0.317871,0.349121]
	6:	[0.325562,0.341187]
	7:	[0.329437,0.337250]
	8:	[0.331383,0.335289]
	9:	[0.332357,0.334311]
	10:	[0.332845,0.333822]
	false.
For this particular function, the width of the result is on the order of {`2^(-P)`} so a more precise value for `R` may require fairly large values of `P` and consequently take some time to calculate.

A more complicated example (from [Introduction to INTERVAL ANALYSIS]) - the elliptic interval of the first kind {`int_0^theta(1-k^2sin^2t)^(-1//2)dt`} with parameters {`theta = 2pi`} and {`k = 0.5`} :
eg
	?- T::real(0,2*pi), K = 1r2, integrate(sqrt(1-K**2*sin(T**2)),T,R,12).
	K = 1r2,
	T::real(0, 6.283185307179587),
	R:: 6.1793... .
Note that this technique can be used to evaluate any integral, e.g., even for those functions that have no derivative. The following calculates the total area under the curve {`2*X+X**2-X**3`} between {`-1`} and {`1`} even though the function value is negative in some parts of the range:
eg
	?- X::real(-1,1),integrate(abs(2*X+X**2-X**3),X,R,10).
	X::real(-1, 1),
	R:: 1.5... .
This implementation (crude Euler) of `integrate/4` demonstrates the concept of applying numerical methods to interval arithmetic but much better methods of numerical integration exist. `library(clpBNR_toolkit)` uses a trapezoidal method and is much more accurate for a modest increase in execution time. This method approximates the function over a sub-interval with a straight line with slope equal to average of the slopes at the ends of the interval. (More details in [Application of Relational Interval Arithmetic to Ordinary Differential Equations].)  However, it requires a function that is continuously differentiable over the range of `X`. If that's not the case the simpler (and cruder) Euler method described above is used. Repeating the examples: 
eg
	?- X::real(0,1), between(2,10,P), integrate(X**2,X,R,P), range(R,[Rl,Rh]), format("~w:\t[~f,~f]\n",[P,Rl,Rh]),fail.
	2:	[0.328125,0.359375]
	3:	[0.332031,0.339844]
	4:	[0.333008,0.334961]
	5:	[0.333252,0.333740]
	6:	[0.333313,0.333435]
	7:	[0.333328,0.333359]
	8:	[0.333332,0.333340]
	9:	[0.333333,0.333335]
	10:	[0.333333,0.333334]
	false.
	
	?- T::real(0,2*pi), K = 1r2, integrate(sqrt(1-K**2*sin(T**2)),T,R,8).  % note decrease in P
	K = 1r2,
	T::real(0, 6.283185307179587),
	R:: 6.18... .
	
	?- X::real(-1,1),integrate(abs(2*X+X**2-X**3),X,R,10).  % non differentiable, same as previous
	X::real(-1, 1),
	R:: 1.5... .

There are many algorithms (Euler (various), Adams-Bashforth, Runge-Kutta, etc.) for performing numerical integration but they all involve multiple steps (subdivisions of the independent variable `X`)` and each step requires an approximation. Using conventional floating point arithmetic necessitates an often complicated process of error analysis to validate any results, but when based on interval arithmetic, the accumulated error is expressed directly in the result. In effect, the error analysis is done automatically as the computation proceeds. In addition, any floating point rounding errors are included in the result, so you have some confidence that the exact result lies within the bounds of the generated answer.

Reducing the size of the step (by increasing `P`) increases the accuracy of the value that is propagated to the next step. But increasing the number of steps may increase the accumulated  rounding errors, which can exceed any gains in the accuracy of the step approximation, i.e., as `P` is increased, the approximation error decreases but the rounding error increases, and may, at some point, dominate. When this occurs, the algorithm is said to be not stable for that function and step size. Thankfully, the effects of instability are apparent in the result and mechanisms to address the problem are described in the next section.
 
##### Solving Ordinary Differential Equations

A differential equation which involves derivatives with respect to a single independent variable and one or more dependant variables is called an *ordinary differential equation* (vs. a *partial differential equation* involving two or more independent variables). Typically solutions to differential equations are subject to the definition of certain conditions, often referred to as initial or boundary conditions depending on whether they apply to one or more than on point, and problems expressed in terms of such equations collectively called boundary value problems. To keep things simple, consider only a single first order differential equation of the form:
math> dy/dx = f(x,y)
Integrating to remove the derivative yields:
math> y = c + int_x f(x,y) dx
If {`x`} is bounded such that {`x_l<=x<=x_u`} and a boundary condition can be specified, i.e., the value of {`y`} at {`x_l`} or {`x_u`}, the value of {`c`} can be determined, leaving integration as the issue to be addressed in solving boundary value problems. Rather than directly providing an `integrate` like predicate (such as that above), `library(clpBNR_toolkit)` provides predicate `boundary_values/2,3` so that these types of problems can be more naturally expressed: 
eg
	boundary_values(X,DYs)
	
	boundary_values(X,DYs,P)
	
	boundary_values(X,DYs,P,Steps)
where `X` is an interval defining the independent variable whose bounds are the range of interest for the problem. `DYs` is a list containing definitions for the dependent variables `Y`'s`; each definition is a compound term of the form:
eg
	dV(Y, PDY, Yi, Yf)
where
* `Y`, the dependent variable
* `PDY` is an expression specifying the partial derivative of `Y` with respect to `X`
* `Yi` is the value of `Y` at the lower bound of `X` (numeric or variable)
* `Yf` is the value of `Y` at the lower bound of `X` (numeric or variable)

Since internally this predicate performs numerical integration, a precision parameter `P` controls the tradeoff between performance and accuracy as in predicate `integrate` described above.

Note that the boundary values (`Yi` and `Yf`) can be either numeric values (or expressions that evaluate to numeric values) or unknowns (i.e., variables). Further, `Yi` and `Yf` will be constrained to be in the domain of `Y`, or the default `real` domain if `Y` is a non-interval variable.

The primary function of this predicate is to find consistent values for the unknown boundary values given the known values. Neither the independent variable (`X`) or or any of the dependent variables (the `Y`'s) are changed in this process.

A simple example should help clarify. Consider the differential equation {`dy//dx = -2xy`} with a single independent variable {`x`} in the range 0..1 and one dependent variable {`y`} with an initial value of {`y(0)=1`}
eg
	?- X::real(0,1), boundary_values(X,[dV(Y, -2*X*Y,1,Yf)]).
	X::real(0, 1),
	Yf:: 0.368... .
This calculates a final value for {`y`} of `0.368...` at {`x`} = 1. You could also calculate the initial value of {`y`} given a final value of {`y(1)=1//e`} (an arithmetic expression):
eg
	?- X::real(0,1), boundary_values(X,[dV(Y, -2*X*Y,Yi,1/e)]).
	X::real(0, 1),
	Yi:: 1.00... .
`P` is a precision control variable which determines the number of subdivisions (`2::P`) of `X` to be used; the default value is determined by the environment flag `clpBNR_default_precision`. It can be used to control the tradeoff between accuracy and compute time:
eg
	?- member(P,[4,6,8,10]), X::real(0,1), boundary_values(X,[dV(Y, -2*X*Y,1,Yf)],P), {Yerr==Yf-1/e}. 
	P = 4,
	X::real(0, 1),
	Yf:: 0.3...,
	Yerr::real(-0.003893884346302834, 0.004852713489142568) ;
	P = 6,
	X::real(0, 1),
	Yf:: 0.368...,
	Yerr::real(-0.00023648491437761043, 0.0002963642925287724) ;
	P = 8,
	X::real(0, 1),
	Yf:: 0.3678...,
	Yerr::real(-1.4687394602475035e-5, 1.8429670169906043e-5) ;
	P = 10,
	X::real(0, 1),
	Yf:: 0.36788...,
	Yerr::real(-9.165651748688219e-7, 1.1504566717612796e-6).
So for this example, each increase in `P` by 2 results in approximately an extra digit of accuracy. But note:
eg
	?- member(P,[4,6,8,10]), X::real(0,1), boundary_values(X,[dV(Y, -2*X*Y,Yi,1/e)],P), {Yerr==Yi-1}.
	P = 4,
	X::real(0, 1),
	Yi:: 1.0...,
	Yerr::real(-0.008159239482386949, 0.005556263802853234) ;
	P = 6,
	X::real(0, 1),
	Yi:: 1.00...,
	Yerr::real(-0.004178671058648331, 0.004015915278919868) ;
	P = 8,
	X::real(0, 1),
	Yi:: 1.0...,
	Yerr::real(-0.01512471230332646, 0.015114539795394899) ;
	P = 10,
	X::real(0, 1),
	Yi::real(-9658.266090581797, 9660.266089946015),
	Yerr::real(-9659.266090581797, 9659.266089946015).

In this case (backwards computation of `Yi` from a final condition) any increase in `P` beyond `6` actually has a detrimental effect in the accuracy of the `Yi` (although it still contains the precise value, so it's not wrong). This would appear to be a symptom of instability in the numerical integration algorithm as discussed above; the accumulated rounding errors with decreased step size is overwhelming any increase in precision due to that decrease. But why does that not occur for the forward calculation ( computing `Yf`)?

The problem occurs because the calculation of `Yi` from a final value  (`1/e` in this example) is done by backwards propagation after the constraint network is built forward from the as yet undefined initial value (default finite real interval). But the rounding errors are accumulated in the forward direction from the rather large initial `Y` domain and this accumulation is more than enough to offset any gains realized in the backward propagation from a precise final value. This suggests constraining `Y` to a smaller initial domain would result in a smaller accumulation of rounding errors and should help mitigate the problem. (As is usually the case, more constraints is a good thing.)

Given that `X` is positive, and the final value of `Y` is `1/e` (also positive), the slope at `Yf` will be negative, so `Y` increases as as `X` decreases. So `Y` will always be positive over the domain of `X`; therefore, the lower bound of `Y` is 0.  The absolute value of the slope is monotonically decreasing until it reaches 0 at `X=0` given the slope at `X=1, Y=1/e` is approximately 0.73, the absolute value of the slope is always less than 1 so a maximum of `Y` over the range is `1+1/e`. Using a conservative domain of `Y::real(0,2)`:
eg
	?- member(P,[4,6,8,10]), X::real(0,1), Y::real(0,2),boundary_values(X,[dV(Y, -2*X*Y,Yi,1/e)],P), {Yerr==Yi-1}.
	P = 4,
	X::real(0, 1),
	Y::real(0, 2),
	Yi:: 1.0...,
	Yerr::real(-0.007912639651729836, 0.006784689838181146) ;
	P = 6,
	X::real(0, 1),
	Y::real(0, 2),
	Yi:: 1.00...,
	Yerr::real(-0.001583608896701283, 0.003393637996669918) ;
	P = 8,
	X::real(0, 1),
	Y::real(0, 2),
	Yi:: 1.00...,
	Yerr::real(-0.0010610419856995623, 0.003450394852820171) ;
	P = 10,
	X::real(0, 1),
	Y::real(0, 2),
	Yi:: 1.0...,
	Yerr::real(-0.005800266930922726, 0.019849898586537185).
This is a much better result over the tested range of `P` than above, but note that increasing `P` is having a minimal effect on the precision of the answer suggesting that the rounding errors are offsetting the effects of any decrease in the step size as `P` increases.

For single value problems (as in this case), the results are over conservative so `absolve` can be used to further "trim" invalid regions from the interval boundaries (at the expense of performance). For the backwards example with unrestricted `Y` domain`:
eg
	?- member(P,[4,6,8,10]), X::real(0,1), boundary_values(X,[dV(Y, -2*X*Y,Yi,1/e)],P), absolve(Yi), {Yerr==Yi-1}.
	P = 4,
	X::real(0, 1),
	Yi:: 1.0...,
	Yerr::real(-0.00548043024698841, 0.0029197418452593382) ;
	P = 6,
	X::real(0, 1),
	Yi:: 1.000...,
	Yerr::real(-0.00043348902155659896, 0.00026256797562251855) ;
	P = 8,
	X::real(0, 1),
	Yi:: 1.000...,
	Yerr::real(-0.00035945248949764697, 0.00016740854668939598) ;
	P = 10,
	X::real(0, 1),
	Yi::real(-300.8520656386373, 92.03909087114431),
	Yerr::real(-301.8520656386373, 91.03909087114431).
For this problem, using `absolve` is actually more effective than increasing `P`; even for unrestricted `Y`, `P=6` with `absolve` provides a tighter solution than any of the previous results. In fact, increasing `P` beyond this value lead to practically imperceptible results and, eventually, instability.

So there exist 3 "levers" for managing the accumulated error: the precision parameter `P`, which is used by the numerical integration algorithm, applying `absolve` to "squeeze" the result, and constraining the independent variable prior to calculating the boundary values. If we use the default value of `P` (i.e., 6) as a baseline, the relative effectiveness of the three techniques are summarized in the tables below (one for the initial boundary problem and one for the final):
.myw
	.tsv
		`Forward  (dV(Y,-2*X*Y, 1, Yf))`		`Time Ratio`	`Error ratio`
		`P=8`									`   3.07`		`    0.06`
		+`absolve/1`							`   2.31`		`    0.40`
		+`Y::real(0,2)`							`   0.47`		`    1.00`
	.tsv
		`Backward (dV(Y,-2*X*Y,Yi,1/e))`		`          `	`           `
		`P=8`									`   3.94`		`    3.66`
		+`absolve/1`							`   1.93`		`    0.85`
		+`Y::real(0,2)`							`   0.21`		`    0.61`
	&	// local styles for table
		@css
			table.my_array { border-collapse:collapse; }
			table.my_array tr td { background:whitesmoke; padding: 4px 16px; }
			table.my_array tr:nth-child(1) td { background:lightgray; }

For this problem set (initial and final), restricting the domains of any independent variables is the most effective and it will always improve execution times. Applying `absolve` to the result is the next best strategy, although there is a time tradeoff to consider. Increasing `P` can also help reduce error but it definitely incurs a time penalty (inreasing `P` by 2, as in this case, quadruples the number of integration steps) and may even result in instability (`Error ration` gets worse), so confirming the benefits is recommended before committing to this strategy.

The arity 4 version of `boundary_values` adds a final argument which is unified with a the list of integration step values of length `2**P`; each value being tuple of the form of `(X,Ys)`. It's primarily intended for use during development (with low values of `P`) or for post processing (e.g., points in a graph).
eg
	?- X::real(0,1), boundary_values(X,[dV(Y, -2*X*Y,1,Yf)],3,Steps),maplist(writeln,Steps).
	0,[1]
	1r8,[_538{real(0.9844295893349677,0.9848011798958015)}]
	1r4,[_488{real(0.939103050831425,0.9406172288888547)}]
	3r8,[_4632{real(0.8679648609134579,0.8714777859918755)}]
	1r2,[_438{real(0.7769307450381604,0.783451629391624)}]
	5r8,[_9064{real(0.6730338450829737,0.6838203935516215)}]
	3r4,[_9012{real(0.5634637285170379,0.580170558332121)}]
	7r8,[_468786{real(0.45465608634680194,0.4795803733327926)}]
	1,[_294{real(0.3515513718582815,0.3880524920547308)}]
	    .
	    .
	    .
Following are a few more examples taken from [Applied Differential Equations, 2nd Ed., M.R. Spiegel].

##### A Falling Paratrooper

>	*A falling paratrooper (and his parachute) weigh 200 lb. The parachute causes an opposing force to act on the paratrooper due to air resistance which is proportional to his velocity. If the downward velocity when the parachute opens is 40 ft./sec., and the air resistance is 80 lb. when the velocity is 20 ft./sec., find the paratrooper's downward velocity at 1 sec., 5 sec. and 10 sec. after the parachute opens.*
 
From Newton's Second Law of Motion ({`F=ma`}), the motion of the paratrooper can be described as:

math>	W/g*(dv)/dt = W-beta*v
Isolating the derivative:
math>	(dv)/dt = g-beta*v*g/W

With {`g=32 ft.//sec.^2, beta=80//20=4, W=200 lb.`}:
eg
	?- G= 32,B=4,W=200, member(Tf,[1,5,10]),T::real(0,Tf), boundary_values(T,[dV(V,G-G*B*V/W,40,Vf)]).
	G = 32,
	B = 4,
	W = 200,
	Tf = 1,
	T::real(0, 1),
	Vf:: 44.727... ;
	G = 32,
	B = 4,
	W = 200,
	Tf = 5,
	T::real(0, 5),
	Vf:: 49.6... ;
	G = 32,
	B = 4,
	W = 200,
	Tf = 10,
	T::real(0, 10),
	Vf::real(45.585783403912075, 54.381162476525745).
The first result (at 1 sec.) looks quite good - 5 digits of accuracy. But it's down to three digits at 5 sec., and the result is quite wide at 10 sec. (For comparison, the exact solution is given by `﻿V is 50-10*exp(-0.64*T)` for a terminal velocity of 50 ft./sec.) In this case, `absolve` is quite effective:
eg
	?- G= 32,B=4,W=200, T::real(0,10), boundary_values(T,[dV(V,G-G*B*V/W,40,Vf)]), absolve(Vf).
	G = 32,
	B = 4,
	W = 200,
	T::real(0, 10),
	Vf::real(49.880402091711716, 50.06622664386094).
And increasing `P` also helps:
eg
	?- G= 32,B=4,W=200, T::real(0,10), boundary_values(T,[dV(V,G-G*B*V/W,40,Vf)],8), absolve(Vf).
	G = 32,
	B = 4,
	W = 200,
	T::real(0, 10),
	Vf:: 50.0... .
Of course there's a tradeoff between a smaller step size and compute time that must be justified.
 
##### Brine Tank

>	*A tank is filled with 10 gal. of brine in which is dissolved 5 lb. of salt. Brine containing 3 lb. of salt per gal. enters the tank at 2 gal./min. and the well stirred mixture leaves at the same rate. How much salt is present after 10 min.? After 30 min.?*
 
If {`A`} is the amount of salt in the tank, {`dA//dt`} is the rate of change of this amount of salt, which is equal to the difference between the rate that salt enters and leaves: {`dA//dt = 2*3 - 2*(A//10)`} or {`d(A)=6-A/5`}. Initial condition: {`A(0)=5`}, so after 10 minutes:
eg
	?- member(Tf,[10,30]), T::real(0,Tf), boundary_values(T,[dV(A,6-A/5,5,Af)]).
	Tf = 10,
	T::real(0, 10),
	Af:: 26.6... ;
	Tf = 30,
	T::real(0, 30),
	Af::real(23.592671270766537, 36.28393528912539).
At 30 minutes the answer is unacceptably wide so increase the number of steps using the precision parameter (without and with `absolve`):`:
eg
	?- T::real(0,30), boundary_values(T,[dV(A,6-A/5,5,Af)],10).
	T::real(0, 30),
	Af:: 29.9... .
	
	?- T::real(0,30), boundary_values(T,[dV(A,6-A/5,5,Af)]), absolve(Af).
	T::real(0, 30),
	Af::real(29.69042702958739, 30.112189862588497).
	
	?- T::real(0,30), boundary_values(T,[dV(A,6-A/5,5,Af)],10), absolve(Af).
	T::real(0, 30),
	Af:: 29.9... .
So either increasing `P` or using `absolve` has a measurable effect, but using both doesn't do much. Also, constraining the initial domain of `A` has no impact since it's an initial (vs. final) boundary problem.

By analysis, equilibrium is reached when the rate of change of {`A`} is 0, i.e.,{`dA//dt=0`}. Solving for {`A`} yields an equilibrium value of 30 lb., which is in agreement with the computed result.

##### Fuzzy Data

In addition to the dependent and independent variables, there may be other intervals representing fuzzy data which may be contained in the differential equation. For example, the flow in the brine tank example may vary by 5% from the nominal value. This can be modelled by an interval `F` with a domain of `real(1.9,2.1)`, so after 10 sec.:
eg
	?- F::real(1.9,2.1), T::real(0,10), boundary_values(T,[dV(A,F*(3-A/10),5,Af)]).
	F::real(1.8999999999999997, 2.1000000000000005),
	T::real(0, 10),
	Af::real(22.047179199371364, 31.391451363505027).
This result is considerably wider than the original seen previously, but is it due to the fuzzy flow value or is something else going on? Since all values are positive, the rate of change of `A` is positive and monotonically increases with `F`, so evaluating at the boundaries should provide accurate (within the limits of the integration algorithm) values of `Af`:
eg
	?- member(F,[1.9,2.1]), T::real(0,10), boundary_values(T,[dV(A,F*(3-A/10),5,Af)]).
	F = 1.9,
	T::real(0, 10),
	Af:: 26.2... ;
	F = 2.1,
	T::real(0, 10),
	Af:: 26.9... .

As a first step, see if `absolve` helps to address any weak convergence issues:
eg
	?- F::real(1.9,2.1), T::real(0,10), boundary_values(T,[dV(A,F*(3-A/10),5,Af)]), absolve(Af).
	F::real(1.8999999999999997, 2.1000000000000005),
	T::real(0, 10),
	Af::real(25.879790829191812, 27.251744579186916).
That actually helped quite a bit, but still not as narrow as it could be. 

Decreasing the step size (increasing `P`):
eg
	?- F::real(1.9,2.1), T::real(0,10), boundary_values(T,[dV(A,F*(3-A/10),5,Af)],9), absolve(Af).
	F::real(1.8999999999999997, 2.1000000000000005),
	T::real(0, 10),
	Af::real(24.90479250163392, 28.118511102029014).
actually made it worse, so it's probably not an instability issue. 

The problem is that any uncertainty in one of "constants" is propagated from each integration step to the next, amplified by the approximation error. The end result is correct in that it contains the "real" value, but it may seem more conservative than need be. But that's the product of the accumulation of uncertainty in the data, approximation errors caused by the integration algorithm and rounding errors, and it may take some effort to separate the individual sources contributing to the error. 

##### Systems of Differential Equations

A useful extension of this "single independent variable, single dependent variable" implementation is to add support for multiple dependent variables as defined by multiple differential equations sharing a single dependent variable, i.e., a set of ordinary differential equations. This requires replacing the single equation with a list of such equations, the `Y` in `Initial` and `Final` values with a list of `Y`'s, and the domain with a list of domains. `integrate/5,6` supports this extended semantics.

`integrate/5,6` supports specifying systems of simultaneous differential equations in this way permitting the solution of more complicated first order and higher order systems as shown in the following examples.

##### Cannon Example

>	*A shell is fired from a cannon which has a muzzle velocity of 160 ft./sec. and is inclined at an angle of 60˚ to the horizontal. Determine the position and velocity of the shell after it is in flight for 2 and 4 sec.*

From Newton's second law, {`dv_x//dt = 0`} and {`dv_y//dt = -g`}. Also {`dx//dt = v_x`} and {`dy//dt = v_y`}. Initial conditions are {`x(0)=0, y(0)=0, v_x(0) = 160 cos(pi//3), v_y(0) = 160 sin(pi//3)`} so:
eg
	?- member(Tf,[2,4]),G=32, Vx0 is 160*cos(pi/3), Vy0 is 160*sin(pi/3), T::real(0,Tf),
	boundary_values(T,[dV(Vx,0,Vx0,Vxf),dV(Vy, -G,Vy0,Vyf),dV(X,Vx,0,Xf),dV(Y,Vy,0,Yf)]),
	{Vf is sqrt(Vxf**2+Vyf**2)}.
	Tf = 2,
	G = 32,
	Vx0 = Vxf, Vxf = 80.00000000000001,
	Vy0 = 138.56406460551017,
	T::real(0, 2),
	Vyf:: 74.5640646055101...,
	Xf:: 160.000000000000...,
	Yf:: 213.12812921102...,
	Vf:: 109.3608692837374... ;
	Tf = 4,
	G = 32,
	Vx0 = Vxf, Vxf = 80.00000000000001,
	Vy0 = 138.56406460551017,
	T::real(0, 4),
	Vyf:: 10.5640646055101...,
	Xf:: 320.00000000000...,
	Yf:: 298.25625842204...,
	Vf:: 80.6944822214592... .
After 4 sec., the shell is travelling a little over 80 ft./sec. and is almost 300 ft. high and 320 ft. down range.

This example uses multiple differential equations to model `X` and `Y` directions but also hints at how to model higher order equations (`d(Vx)` is the second derivative of `X`).

##### Higher Order Differential Equations

The *n*-th order differential equation in the dependent variable {`y`} and the independent {`x`} can be written in functional form:

math> F(x,y,y^1,y^2,...,y^(n-1),y^(n)) = 0

where the superscripts denote differentiation with respect to {`x`}. The necessary initial condition is that at {`x=x_0`} the values for {`y`} and its first {`n-1`} derivatives are assigned. A helpful convention for naming Prolog variables is to use `Yn` for the {`n`}th derivative of `Y`. To illustrate this, the paratrooper example can be extended to produce the displacement as well as the velocity (`X` and `X1` respectively):
eg
	?- member(Tf,[1,5,10]), G=32,B=4,W=200, T::real(0,Tf), boundary_values(T,[dV(X1,G-G*B*X1/W,40,X1f),dV(X,X1,0,Xf)]).
	Tf = 1,
	G = 32,
	B = 4,
	W = 200,
	T::real(0, 1),
	X1f:: 44.727...,
	Xf:: 42.614... ;
	Tf = 5,
	G = 32,
	B = 4,
	W = 200,
	T::real(0, 5),
	X1f:: 49.6...,
	Xf::real(234.94958971967435, 235.07337990669006) ;
	Tf = 10,
	G = 32,
	B = 4,
	W = 200,
	T::real(0, 10),
	X1f::real(45.46960763158747, 54.49733824885036),
	Xf::real(477.3479686566565, 491.4536784051594).
Perhaps this is getting unacceptably wide at `Tf=10` so here's a case where decreasing the step size provides a significant improvement:
eg
	?- member(Tf,[1,5,10]), G=32,B=4,W=200, T::real(0,Tf), boundary_values(T,[dV(X1,G-G*B*X1/W,40,X1f),dV(X,X1,0,Xf)],9).
	Tf = 1,
	G = 32,
	B = 4,
	W = 200,
	T::real(0, 1),
	X1f:: 44.72707...,
	Xf:: 42.61394... ;
	Tf = 5,
	G = 32,
	B = 4,
	W = 200,
	T::real(0, 5),
	X1f:: 49.59...,
	Xf:: 235.01... ;
	Tf = 10,
	G = 32,
	B = 4,
	W = 200,
	T::real(0, 10),
	X1f::real(49.923512910181806, 50.04325871356631),
	Xf::real(484.307408260046, 484.494511077847).
 
##### Vibrating Mass Example

>	*(The displacement {`x`} of a vibrating mass from it's equilibrium position is given by the differential equation {`(d^2x)/(dt^2)+3*dx/dt+5*x = cos 2*t`} where {`x=0`} and {`dx//dt=4`} when {`t=0`}. Find {`x`} and {`dx//dt`} at {`t=3`}.)*
eg
	?- T::real(0,3r10), boundary_values(T,[dV(X1,cos(2*T)-3*X1-5*X,4,X1f),dV(X,X1,0,Xf)]).
	T::real(0, 0.3),
	X1f:: 1.31...,
	Xf:: 0.765... .

##### Rocket Example

>	*A rocket has a mass of 25,000 kg. of which 20,000 kg. is fuel. The rocket's exhaust velocity is 400 m./sec. (relative to the rocket) requiring a loss of 1000 kg. of fuel per sec. The rocket starts on the ground and travels vertically upward with the only external force being gravity. Find the velocity and height of the rocket after 15, 20, and 30 sec.*

Rockets work through Newton's second law of motion, i.e., the time rate of change in momentum is equal to the force acting on the object. This is expressed by the differential equation {`F=M*(dV)/dt - e_v*(dM)/dt`}. where {`M`} is the mass of the rocket(and fuel) and  {`V`} and {`e_v`} are the velocities of the rocket and expelled gas respectively. For an initial mass of {`M_0`} and an burn rate of {`b`}, the mass of the rocket as a function of time is {`M_0-b*t`} so:

math> (M_0-b*t)*(dV)/dt - b*e_v = 0

Re-writing and adding the force of gravity produces:

math> (dV)/dt = -g+(b*e_v)/(M_0-b*t)

Using the data in the example and `Tf=15`:
eg
	?- G=9.8, M0=25000, B=1000, Ev=400, T::real(0,15), boundary_values(T,[dV(X1, -G+(B*Ev)/(M0-B*T),0,X1f),dV(X,X1,0,Xf)]).
	G = 9.8,
	M0 = 25000,
	B = 1000,
	Ev = 400,
	T::real(0, 15),
	X1f:: 219.5...,
	Xf::real(1232.2491681428976, 1232.776558960208).
So after 15 sec. the rocket is travelling at 220 m./sec. at a height of 1232 m. The same query form could be used for 20 sec. but note that at 20 sec. the fuel is exhausted. So a different equation applies for `T>20`; one involving just the force of gravity. The final values for `T=20` can be used as the initial values to calculate the velocity and height at `T=30`. Note that we need two different independent variables `T00` and `T20` to represent the two ranges of `T``:
eg
	?- G=9.8, M0=25000, B=1000, Ev=400,
	T00::real( 0,20), boundary_values(T00,[dV(X1, -G+(B*Ev)/(M0-B*T00),0,V20),dV(X,X1,0,H20)]),
	T20::real(20,30), boundary_values(T20,[dV(X1, -G,V20,V30),dV(X,X1,H20,H30)]).
	G = 9.8,
	M0 = 25000,
	B = 1000,
	Ev = 400,
	T00::real(0, 20),
	V20::real(447.7126142866085, 448.0876142866101),
	H20::real(2820.6550483654983, 2823.4688087684085),
	T20::real(20, 30),
	V30::real(349.7126142866049, 350.08761428661376),
	H30::real(6807.781191231543, 6814.344951634553).
When the fuel is expended at 20 sec., the rocket has reached a (peak) velocity of 448 m./sec and continues to coast reaching a height of approximately 6810 m. after 30 sec.

##### Summary

This topic just covers a small but useful subclass of science and engineering problems involving differential equations, namely initial (or final) value problems using ordinary differential equations. And the examples just cover a few of the many possible applications in mechanics, heat flow, electrical circuits, optics, radioactivity, chemistry, etc. It's not uncommon that the equations that arise are incapable of exact (analytical) treatment and numerical methods are required. A particular advantage of using intervals in this domain is automatic error analysis which provides explicit evidence of algorithm instability which may not be so obvious using conventional floating point methods.

<#TableOfContents>

&
	[Application of Relational Interval Arithmetic to Ordinary Differential Equations] <- link https://ridgeworks.github.io/BNRProlog-Papers/docs/ODEsOlder.pdf
	[Applied Differential Equations, 2nd Ed., M.R. Spiegel] <- link https://www.scribd.com/document/357337779/Murray-R-Spiegel-Applied-Differential-Equations-Prentice-Hall-Inc-1967
